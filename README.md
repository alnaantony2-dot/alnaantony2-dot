# Hi, Iâ€™m Alna ğŸ‘‹

Undergraduate student in **Mathematics & Artificial Intelligence** building **real-world robotics perception systems** with a focus on **Vision-Language Models (VLMs)** and **efficient edge AI**.

I work on AI that runs **reliably on robots**, not just on GPUs.

---

## ğŸ§  What I Work On
- Vision-Language Models for **robot perception**
- Real-time **entry/exit counting** using spatial + semantic reasoning
- **Human behavior analysis** (anger detection, loitering, overcrowding)
- **Safety monitoring**: fire, smoke, weapons, unauthorized access
- Edge-friendly AI (CPU-only, low RAM, no heavy frameworks)

---

## ğŸ¤– Current Project
### VLM Based Crowd Monitoring System
A lightweight **VLM-powered perception stack** designed for managing crowd.


---

## ğŸ”¬ Technical Focus
- Vision-Language Models (BLIP, lightweight multimodal models)
- YOLO-based detection + tracking
- Event-driven logic (not frame-by-frame hacks)
- Door-state reasoning instead of naive line-crossing
- CPU-first deployment mindset
- Modular, debuggable robotics code

---

## ğŸ› ï¸ Tools & Stack
- Python, OpenCV
- PyTorch
- YOLO (Ultralytics)
- Vision-Language Models
- Raspberry Pi, Arduino (robotics integration)
- Telegram Bots for alerting
- Linux & Git

---

## ğŸ¯ Interests
- Robotics perception & autonomy  
- Edge AI and model optimization  
- Human-aware AI systems  
- Safety-critical applications  
- Applied research with real deployments  

---

## ğŸ“Œ Career Goal
To work on **robotics and applied AI systems** where perception, reasoning, and efficiency matter more than benchmarks.

---

## ğŸ“« Letâ€™s Connect
- GitHub: https://github.com/alnaantony2-dot


